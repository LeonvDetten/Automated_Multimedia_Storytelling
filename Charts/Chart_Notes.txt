https://mermaid.live/

erDiagram
    USER ||--o{ STORY : creates
    STORY ||--o{ MEDIA_ASSET : contains
    STORY }|--|{ CHARACTER : features
    STORY ||--o{ PIPELINE_LOG : generates

    STORY {
        uuid id PK
        string title
        text input_prompt
        text full_text
        string status
        timestamp created_at
    }

    CHARACTER {
        uuid id PK
        string name
        text description
        vector embedding "Used for RAG"
        json metadata
    }

    MEDIA_ASSET {
        uuid id PK
        uuid story_id FK
        enum type "audio, image, video"
        string file_url
        text prompt
        float timestamp_offset
    }

    PIPELINE_LOG {
        uuid id PK
        uuid story_id FK
        string step_name
        int duration_ms
        string status
    }





graph LR
    %% High-Contrast / Deep Mode Styles
    classDef startNode fill:#005f73,stroke:#0a9396,stroke-width:2px,color:#fff;
    classDef logicNode fill:#94d2bd,stroke:#005f73,stroke-width:2px,color:#000;
    classDef dbNode fill:#ee9b00,stroke:#bb3e03,stroke-width:2px,color:#000;
    classDef mediaNode fill:#0a9396,stroke:#005f73,stroke-width:2px,color:#fff;
    classDef dashNode fill:#bb3e03,stroke:#ae2012,stroke-width:2px,color:#fff;

    %% User Input
    Start((Start)) --> Input[User Input]
    class Start input
    class Input startNode

    %% Core Logic (Phase 1)
    Input --> RAG{RAG Check}
    RAG -- Query --> DB[(Database)]
    DB -- Lore --> RAG
    RAG --> LLM[Generate Text]
    LLM --> TextReady[Final Script]
    
    class RAG,LLM,TextReady logicNode
    class DB dbNode

    %% Multimedia Pipeline (Phase 2)
    TextReady --> TTS[Audio Gen]
    TextReady --> VisualGen[Visual Gen]
    
    TTS --> Sync[Final Sync]
    VisualGen --> Sync

    %% Output
    Sync --> Final((Result))
    class TTS,VisualGen,Sync mediaNode
    class Final startNode

    %% Website Monitoring
    LLM -.-> Web[Live Tracker]
    VisualGen -.-> Web
    TTS -.-> Web
    class Web dashNode